{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zwxEG1CJWuEa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwxEG1CJWuEa",
        "outputId": "916c1ead-33e1-484f-e0f2-278dde69ae36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3149a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3149a3d",
        "outputId": "805e6ad9-03a5-4113-a0bb-7d001b97a6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   index  AADT_VN  BEGIN_POIN  COUNTY_COD  END_POINT  IRI_VN  IS_IMPROVED  \\\n",
            "0      0    44290         5.3          97        5.4      44            0   \n",
            "1      1    44750         5.3          97        5.4      48            0   \n",
            "2      2    45760         5.3          97        5.4      80            0   \n",
            "3      3    48670         5.3          97        5.4      43            1   \n",
            "4      4    49080         5.3          97        5.4      39            1   \n",
            "\n",
            "       ROUTE_ID  SPEED_LIMI  THROUGH_LA  YEAR_RECOR  curval  \\\n",
            "0  IN0000100000        60.0           4        2013     263   \n",
            "1  IN0000100000        60.0           4        2014     268   \n",
            "2  IN0000100000        60.0           4        2015     192   \n",
            "3  IN0000100000        70.0           4        2016     176   \n",
            "4  IN0000100000        70.0           4        2017     205   \n",
            "\n",
            "                                      geometry_paths  tmiles  tons  value  \n",
            "0  [[[-88.31770505199995, 30.49976574300007], [-8...      15   716    270  \n",
            "1  [[[-88.31770505199995, 30.49976574300007], [-8...      16   750    286  \n",
            "2  [[[-88.31770505199995, 30.49976574300007], [-8...      17   778    292  \n",
            "3  [[[-88.31770505199995, 30.49976574300007], [-8...      17   783    311  \n",
            "4  [[[-88.12412879499999, 30.698415469000054], [-...      17   771    314  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7119 entries, 0 to 7118\n",
            "Data columns (total 16 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   index           7119 non-null   int64  \n",
            " 1   AADT_VN         7119 non-null   int64  \n",
            " 2   BEGIN_POIN      7119 non-null   float64\n",
            " 3   COUNTY_COD      7119 non-null   int64  \n",
            " 4   END_POINT       7119 non-null   float64\n",
            " 5   IRI_VN          7119 non-null   int64  \n",
            " 6   IS_IMPROVED     7119 non-null   int64  \n",
            " 7   ROUTE_ID        7119 non-null   object \n",
            " 8   SPEED_LIMI      7119 non-null   float64\n",
            " 9   THROUGH_LA      7119 non-null   int64  \n",
            " 10  YEAR_RECOR      7119 non-null   int64  \n",
            " 11  curval          7119 non-null   int64  \n",
            " 12  geometry_paths  7119 non-null   object \n",
            " 13  tmiles          7119 non-null   int64  \n",
            " 14  tons            7119 non-null   int64  \n",
            " 15  value           7119 non-null   int64  \n",
            "dtypes: float64(3), int64(11), object(2)\n",
            "memory usage: 890.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow import keras\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/Updated_FinalFilteredCombined.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Print the column names and their data types\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FVrTHU6iDKjj",
      "metadata": {
        "id": "FVrTHU6iDKjj"
      },
      "outputs": [],
      "source": [
        "df.index = range(1, len(df) + 1)\n",
        "df.reset_index(inplace=True, names=['new_index'])  # Add 'new_index' as a column\n",
        "\n",
        "# Method 2: Creating a new column directly\n",
        "df['new_index'] = range(1, len(df) + 1)\n",
        "\n",
        "# If you want 'index' instead of 'new_index'\n",
        "df.rename(columns={'new_index': 'index'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b4e2c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3b4e2c2",
        "outputId": "7b988449-e387-4d94-96fb-2583288c0800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['index', 'index', 'AADT_VN', 'BEGIN_POIN', 'COUNTY_COD', 'END_POINT',\n",
            "       'IRI_VN', 'IS_IMPROVED', 'ROUTE_ID', 'SPEED_LIMI', 'THROUGH_LA',\n",
            "       'YEAR_RECOR', 'curval', 'geometry_paths', 'tmiles', 'tons', 'value'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0eb2df",
      "metadata": {
        "id": "0e0eb2df"
      },
      "outputs": [],
      "source": [
        "df['index'] = df['index'] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24e11c9b",
      "metadata": {
        "id": "24e11c9b"
      },
      "outputs": [],
      "source": [
        "train_months = df['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359bd1b8",
      "metadata": {
        "id": "359bd1b8"
      },
      "outputs": [],
      "source": [
        "cols = ['AADT_VN', 'BEGIN_POIN', 'COUNTY_COD', 'END_POINT', 'IS_IMPROVED', 'SPEED_LIMI', 'THROUGH_LA', 'YEAR_RECOR', 'curval', 'tmiles', 'tons', 'value']\n",
        "target_col = 'IRI_VN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7edc89",
      "metadata": {
        "id": "8a7edc89"
      },
      "outputs": [],
      "source": [
        "df_for_training = df[cols + [target_col]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5bea61",
      "metadata": {
        "id": "8a5bea61"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(df_for_training)\n",
        "df_for_training_scaled = scaler.transform(df_for_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4fd62b",
      "metadata": {
        "id": "fa4fd62b"
      },
      "outputs": [],
      "source": [
        "trainX = []\n",
        "trainY = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48be5cf4",
      "metadata": {
        "id": "48be5cf4"
      },
      "outputs": [],
      "source": [
        "n_future = 1\n",
        "n_past = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52289938",
      "metadata": {
        "id": "52289938"
      },
      "outputs": [],
      "source": [
        "for i in range(n_past, len(df_for_training_scaled) - n_future + 1):\n",
        "    trainX.append(df_for_training_scaled[i - n_past:i, 0:len(cols)])  # Only features\n",
        "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, len(cols)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dae9f17",
      "metadata": {
        "id": "0dae9f17"
      },
      "outputs": [],
      "source": [
        "trainX, trainY = np.array(trainX), np.array(trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9281c255",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9281c255",
        "outputId": "74ab785b-3782-4a73-c322-6687eb1d865f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainX shape == (7111, 8, 12).\n",
            "trainY shape == (7111, 1).\n"
          ]
        }
      ],
      "source": [
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed6bfc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fed6bfc7",
        "outputId": "ee3840db-1adc-4b1e-acc0-6515d3e94274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.80518051]\n",
            " [-0.32214006]\n",
            " [-0.48315354]\n",
            " ...\n",
            " [ 5.58168772]\n",
            " [ 1.43111789]\n",
            " [ 1.39533711]]\n"
          ]
        }
      ],
      "source": [
        "print(trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c83a803",
      "metadata": {
        "id": "6c83a803"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T-SyO334aZav",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-SyO334aZav",
        "outputId": "a2f412c9-558a-4e02-9fe2-c364d221565c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 09m 49s]\n",
            "val_loss: 0.48091359436511993\n",
            "\n",
            "Best val_loss So Far: 0.43463167548179626\n",
            "Total elapsed time: 02h 50m 51s\n",
            "Results summary\n",
            "Results in tcn_tuning/tcn_reg_dropout_1\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 15 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 1.423617105148514e-05\n",
            "dropout_1: 0.0\n",
            "dropout_2: 0.2\n",
            "dropout_3: 0.1\n",
            "dropout_4: 0.0\n",
            "Score: 0.43463167548179626\n",
            "\n",
            "Trial 10 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 1.2170633740470043e-05\n",
            "dropout_1: 0.30000000000000004\n",
            "dropout_2: 0.4\n",
            "dropout_3: 0.4\n",
            "dropout_4: 0.1\n",
            "Score: 0.440905898809433\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 3.6937225014755196e-05\n",
            "dropout_1: 0.4\n",
            "dropout_2: 0.30000000000000004\n",
            "dropout_3: 0.30000000000000004\n",
            "dropout_4: 0.0\n",
            "Score: 0.46908338367938995\n",
            "\n",
            "Trial 19 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 5.794155666227713e-05\n",
            "dropout_1: 0.2\n",
            "dropout_2: 0.30000000000000004\n",
            "dropout_3: 0.30000000000000004\n",
            "dropout_4: 0.4\n",
            "Score: 0.48091359436511993\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 3.3218045599338696e-05\n",
            "dropout_1: 0.30000000000000004\n",
            "dropout_2: 0.0\n",
            "dropout_3: 0.2\n",
            "dropout_4: 0.1\n",
            "Score: 0.48232828080654144\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 5.154994394291512e-05\n",
            "dropout_1: 0.4\n",
            "dropout_2: 0.2\n",
            "dropout_3: 0.1\n",
            "dropout_4: 0.2\n",
            "Score: 0.49351808428764343\n",
            "\n",
            "Trial 11 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 0.00016618360336245936\n",
            "dropout_1: 0.1\n",
            "dropout_2: 0.1\n",
            "dropout_3: 0.1\n",
            "dropout_4: 0.1\n",
            "Score: 0.5276239216327667\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 6.894348101638672e-05\n",
            "dropout_1: 0.2\n",
            "dropout_2: 0.0\n",
            "dropout_3: 0.1\n",
            "dropout_4: 0.1\n",
            "Score: 0.5374950766563416\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 0.00016598531421832164\n",
            "dropout_1: 0.2\n",
            "dropout_2: 0.1\n",
            "dropout_3: 0.2\n",
            "dropout_4: 0.0\n",
            "Score: 0.5397399961948395\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "l2_reg: 0.00022008956917507702\n",
            "dropout_1: 0.2\n",
            "dropout_2: 0.4\n",
            "dropout_3: 0.0\n",
            "dropout_4: 0.0\n",
            "Score: 0.5463647246360779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "\n",
        "def build_tcn_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    l2_reg = hp.Float('l2_reg', min_value=1e-5, max_value=1e-3, sampling='log')\n",
        "\n",
        "    model.add(Conv1D(filters=128, kernel_size=2, padding='causal', activation='relu', dilation_rate=1,\n",
        "                     kernel_regularizer=l1(l2_reg)))\n",
        "    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    model.add(Conv1D(filters=96, kernel_size=2, padding='causal', activation='relu', dilation_rate=2,\n",
        "                     kernel_regularizer=l1(l2_reg)))\n",
        "    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    model.add(Conv1D(filters=96, kernel_size=3, padding='causal', activation='relu', dilation_rate=4,\n",
        "                     kernel_regularizer=l1(l2_reg)))\n",
        "    model.add(Dropout(hp.Float('dropout_3', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "    model.add(Conv1D(filters=96, kernel_size=3, padding='causal', activation='relu', dilation_rate=4,\n",
        "                     kernel_regularizer=l1(l2_reg)))\n",
        "    model.add(Dropout(hp.Float('dropout_4', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l1(l2_reg)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.00030508), loss='mse')\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_tcn_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=2,\n",
        "    directory='tcn_tuning',\n",
        "    project_name='tcn_reg_dropout_1'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[EarlyStopping(patience=10)])\n",
        "\n",
        "tuner.results_summary()\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lEdeb2615Mki",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lEdeb2615Mki",
        "outputId": "cf613a2c-bbec-4b0c-ff72-77a772be163c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from tcn_tuning/my_tcn_tuning/tuner0.json\n",
            "Search space summary\n",
            "Default search space size: 18\n",
            "num_tcn_blocks (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "filters_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "dropout_0 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "filters_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "dropout_1 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "units_dense (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
            "filters_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "dropout_2 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "filters_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "dropout_3 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "filters_4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "kernel_size_4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "dropout_4 (Float)\n",
            "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
            "Results summary\n",
            "Results in tcn_tuning/my_tcn_tuning\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_loss\", direction=\"min\")\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 5\n",
            "filters_0: 128\n",
            "kernel_size_0: 2\n",
            "dropout_0: 0.4\n",
            "filters_1: 96\n",
            "kernel_size_1: 2\n",
            "dropout_1: 0.30000000000000004\n",
            "units_dense: 96\n",
            "learning_rate: 0.0003050774916361882\n",
            "filters_2: 96\n",
            "kernel_size_2: 2\n",
            "dropout_2: 0.1\n",
            "filters_3: 32\n",
            "kernel_size_3: 3\n",
            "dropout_3: 0.0\n",
            "filters_4: 96\n",
            "kernel_size_4: 3\n",
            "dropout_4: 0.1\n",
            "Score: 0.3755822628736496\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 3\n",
            "filters_0: 128\n",
            "kernel_size_0: 5\n",
            "dropout_0: 0.1\n",
            "filters_1: 64\n",
            "kernel_size_1: 2\n",
            "dropout_1: 0.30000000000000004\n",
            "units_dense: 96\n",
            "learning_rate: 0.0009895249588496025\n",
            "filters_2: 32\n",
            "kernel_size_2: 2\n",
            "dropout_2: 0.0\n",
            "Score: 0.4011695384979248\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 3\n",
            "filters_0: 128\n",
            "kernel_size_0: 4\n",
            "dropout_0: 0.4\n",
            "filters_1: 32\n",
            "kernel_size_1: 2\n",
            "dropout_1: 0.4\n",
            "units_dense: 32\n",
            "learning_rate: 0.00045072104393307306\n",
            "filters_2: 128\n",
            "kernel_size_2: 5\n",
            "dropout_2: 0.2\n",
            "filters_3: 32\n",
            "kernel_size_3: 5\n",
            "dropout_3: 0.2\n",
            "filters_4: 64\n",
            "kernel_size_4: 4\n",
            "dropout_4: 0.0\n",
            "Score: 0.40724751353263855\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 3\n",
            "filters_0: 128\n",
            "kernel_size_0: 2\n",
            "dropout_0: 0.2\n",
            "filters_1: 128\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.1\n",
            "units_dense: 32\n",
            "learning_rate: 0.001719120591054936\n",
            "filters_2: 128\n",
            "kernel_size_2: 3\n",
            "dropout_2: 0.0\n",
            "Score: 0.4139952212572098\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 3\n",
            "filters_0: 96\n",
            "kernel_size_0: 4\n",
            "dropout_0: 0.2\n",
            "filters_1: 96\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.30000000000000004\n",
            "units_dense: 64\n",
            "learning_rate: 0.0008053201250101636\n",
            "filters_2: 128\n",
            "kernel_size_2: 3\n",
            "dropout_2: 0.2\n",
            "filters_3: 32\n",
            "kernel_size_3: 3\n",
            "dropout_3: 0.4\n",
            "Score: 0.4163687080144882\n",
            "\n",
            "Trial 18 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 5\n",
            "filters_0: 128\n",
            "kernel_size_0: 4\n",
            "dropout_0: 0.0\n",
            "filters_1: 64\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.2\n",
            "units_dense: 32\n",
            "learning_rate: 0.0001863673495940696\n",
            "filters_2: 96\n",
            "kernel_size_2: 5\n",
            "dropout_2: 0.0\n",
            "filters_3: 128\n",
            "kernel_size_3: 3\n",
            "dropout_3: 0.4\n",
            "filters_4: 32\n",
            "kernel_size_4: 3\n",
            "dropout_4: 0.1\n",
            "Score: 0.4191603511571884\n",
            "\n",
            "Trial 17 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 5\n",
            "filters_0: 128\n",
            "kernel_size_0: 4\n",
            "dropout_0: 0.1\n",
            "filters_1: 64\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.2\n",
            "units_dense: 64\n",
            "learning_rate: 0.00014441230321073488\n",
            "filters_2: 96\n",
            "kernel_size_2: 2\n",
            "dropout_2: 0.0\n",
            "filters_3: 96\n",
            "kernel_size_3: 3\n",
            "dropout_3: 0.2\n",
            "filters_4: 128\n",
            "kernel_size_4: 5\n",
            "dropout_4: 0.0\n",
            "Score: 0.4207124263048172\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 2\n",
            "filters_0: 128\n",
            "kernel_size_0: 5\n",
            "dropout_0: 0.2\n",
            "filters_1: 64\n",
            "kernel_size_1: 2\n",
            "dropout_1: 0.2\n",
            "units_dense: 96\n",
            "learning_rate: 0.002172516847626195\n",
            "filters_2: 96\n",
            "kernel_size_2: 2\n",
            "dropout_2: 0.0\n",
            "filters_3: 32\n",
            "kernel_size_3: 3\n",
            "dropout_3: 0.0\n",
            "filters_4: 32\n",
            "kernel_size_4: 4\n",
            "dropout_4: 0.30000000000000004\n",
            "Score: 0.42310644686222076\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 5\n",
            "filters_0: 32\n",
            "kernel_size_0: 3\n",
            "dropout_0: 0.0\n",
            "filters_1: 64\n",
            "kernel_size_1: 2\n",
            "dropout_1: 0.2\n",
            "units_dense: 96\n",
            "learning_rate: 0.00031510705629096133\n",
            "filters_2: 128\n",
            "kernel_size_2: 2\n",
            "dropout_2: 0.4\n",
            "filters_3: 128\n",
            "kernel_size_3: 2\n",
            "dropout_3: 0.4\n",
            "filters_4: 32\n",
            "kernel_size_4: 2\n",
            "dropout_4: 0.0\n",
            "Score: 0.4231799244880676\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "num_tcn_blocks: 4\n",
            "filters_0: 64\n",
            "kernel_size_0: 5\n",
            "dropout_0: 0.2\n",
            "filters_1: 128\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.1\n",
            "units_dense: 32\n",
            "learning_rate: 0.0006363719363340232\n",
            "filters_2: 64\n",
            "kernel_size_2: 4\n",
            "dropout_2: 0.0\n",
            "filters_3: 32\n",
            "kernel_size_3: 2\n",
            "dropout_3: 0.0\n",
            "Score: 0.4255574494600296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_tcn_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # TCN Blocks (you can add more)\n",
        "    for i in range(hp.Int('num_tcn_blocks', min_value=2, max_value=5)):\n",
        "        model.add(Conv1D(\n",
        "            filters=hp.Int(f'filters_{i}', min_value=32, max_value=128, step=32),\n",
        "            kernel_size=hp.Int(f'kernel_size_{i}', min_value=2, max_value=5),\n",
        "            padding='causal',\n",
        "            activation='relu',\n",
        "            dilation_rate=2**i  # Example dilation\n",
        "        ))\n",
        "        model.add(Dropout(hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(hp.Int('units_dense', min_value=32, max_value=128, step=32), activation='relu'))\n",
        "    model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
        "        loss='mse'\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_tcn_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=2,\n",
        "    directory='tcn_tuning',  # Directory to save tuning results\n",
        "    project_name='my_tcn_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(patience=10)]\n",
        ")\n",
        "\n",
        "tuner.results_summary()\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160o8MCs2nxJ",
      "metadata": {
        "id": "160o8MCs2nxJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def build_tcn_model(input_shape, output_units):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))  # Input layer\n",
        "\n",
        "    # Temporal Convolutional Blocks\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', dilation_rate=1))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', dilation_rate=2))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', dilation_rate=4))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))  # Dropout for regularization\n",
        "    model.add(Dense(output_units))  # Output layer\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# --- Usage in your code ---\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (n_past, num_features)\n",
        "output_units = trainY.shape[1]  # 1 (for your target variable)\n",
        "\n",
        "tcn_model = build_tcn_model(input_shape, output_units)\n",
        "tcn_model.summary()\n",
        "\n",
        "# --- Callbacks for training ---\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# --- Train the TCN ---\n",
        "tcn_history = tcn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=120,\n",
        "    batch_size=16,\n",
        "    validation_split=0.1,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# --- Evaluate ---\n",
        "y_pred_tcn = tcn_model.predict(X_test)\n",
        "mse_tcn = mean_squared_error(y_test, y_pred_tcn)  # Assuming y_test is still available\n",
        "print(f\"TCN Mean Squared Error: {mse_tcn}\")\n",
        "\n",
        "# --- R2 Score ---\n",
        "y_train_pred_tcn = tcn_model.predict(X_train)\n",
        "r2_train_tcn = r2_score(y_train, y_train_pred_tcn)\n",
        "r2_test_tcn = r2_score(y_test, y_pred_tcn)\n",
        "\n",
        "print(f'TCN Training R²: {r2_train_tcn}')\n",
        "print(f'TCN Test R²: {r2_test_tcn}')\n",
        "\n",
        "# --- Visualization ---  (Adapt as needed)\n",
        "plt.plot(tcn_history.history['loss'], label='TCN Training Loss')\n",
        "plt.plot(tcn_history.history['val_loss'], label='TCN Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9661db6a",
      "metadata": {
        "id": "9661db6a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, kernel_regularizer=l1(0.00001)))\n",
        "model.add(LSTM(256, activation='relu', return_sequences=False, kernel_regularizer=l1(0.00001)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1], kernel_regularizer=l1(0.00001)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b59baae",
      "metadata": {
        "id": "5b59baae"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.0004\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fe4100",
      "metadata": {
        "id": "38fe4100"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=200, batch_size=16, validation_split=0.1, verbose=1)\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ed577b",
      "metadata": {
        "id": "63ed577b"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_original = np.zeros((y_pred.shape[0], df_for_training.shape[1])) # Dummy array with correct number of columns\n",
        "y_pred_original[:, -1] = y_pred[:, 0]  # Place predictions in the last column\n",
        "y_pred_original = scaler.inverse_transform(y_pred_original)[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237c4db2",
      "metadata": {
        "id": "237c4db2"
      },
      "outputs": [],
      "source": [
        "# Create a dummy array for y_test as well\n",
        "y_test_original = np.zeros((y_test.shape[0], df_for_training.shape[1]))\n",
        "y_test_original[:, -1] = y_test[:, 0]\n",
        "y_test_original = scaler.inverse_transform(y_test_original)[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ed732c",
      "metadata": {
        "id": "35ed732c"
      },
      "outputs": [],
      "source": [
        "print(y_pred_original)\n",
        "print(y_test_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e99bff",
      "metadata": {
        "id": "21e99bff"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test_original, label='Actual')\n",
        "plt.plot(y_pred_original, label='Predicted')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Actual vs. Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daddc23e",
      "metadata": {
        "id": "daddc23e"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(y_test_original, y_pred_original)\n",
        "print(f'Mean Squared Error: {mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce9427b",
      "metadata": {
        "id": "3ce9427b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R² for the training set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "y_train_pred_original = np.zeros((y_train_pred.shape[0], df_for_training.shape[1]))\n",
        "y_train_pred_original[:, -1] = y_train_pred[:, 0]\n",
        "y_train_pred_original = scaler.inverse_transform(y_train_pred_original)[:, -1]\n",
        "\n",
        "y_train_original = np.zeros((y_train.shape[0], df_for_training.shape[1]))\n",
        "y_train_original[:, -1] = y_train[:, 0]\n",
        "y_train_original = scaler.inverse_transform(y_train_original)[:, -1]\n",
        "\n",
        "r2_train = r2_score(y_train_original, y_train_pred_original)\n",
        "print(f'R² score for training set: {r2_train}')\n",
        "\n",
        "# Calculate R² for the test set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "y_test_pred_original = np.zeros((y_test_pred.shape[0], df_for_training.shape[1]))\n",
        "y_test_pred_original[:, -1] = y_test_pred[:, 0]\n",
        "y_test_pred_original = scaler.inverse_transform(y_test_pred_original)[:, -1]\n",
        "\n",
        "y_test_original = np.zeros((y_test.shape[0], df_for_training.shape[1]))\n",
        "y_test_original[:, -1] = y_test[:, 0]\n",
        "y_test_original = scaler.inverse_transform(y_test_original)[:, -1]\n",
        "\n",
        "r2_test = r2_score(y_test_original, y_test_pred_original)\n",
        "print(f'R² score for test set: {r2_test}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}