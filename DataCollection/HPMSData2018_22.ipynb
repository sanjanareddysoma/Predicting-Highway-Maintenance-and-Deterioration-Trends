{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 337152\n",
      "Fetching records 0 to 2000...\n",
      "Fetching records 2000 to 4000...\n",
      "Fetching records 4000 to 6000...\n",
      "Fetching records 6000 to 8000...\n",
      "Fetching records 8000 to 10000...\n",
      "Fetching records 10000 to 12000...\n",
      "Fetching records 12000 to 14000...\n",
      "Fetching records 14000 to 16000...\n",
      "Fetching records 16000 to 18000...\n",
      "Fetching records 18000 to 20000...\n",
      "Fetching records 20000 to 22000...\n",
      "Fetching records 22000 to 24000...\n",
      "Fetching records 24000 to 26000...\n",
      "Fetching records 26000 to 28000...\n",
      "Fetching records 28000 to 30000...\n",
      "Fetching records 30000 to 32000...\n",
      "Fetching records 32000 to 34000...\n",
      "Fetching records 34000 to 36000...\n",
      "Fetching records 36000 to 38000...\n",
      "Fetching records 38000 to 40000...\n",
      "Fetching records 40000 to 42000...\n",
      "Fetching records 42000 to 44000...\n",
      "Fetching records 44000 to 46000...\n",
      "Fetching records 46000 to 48000...\n",
      "Fetching records 48000 to 50000...\n",
      "Fetching records 50000 to 52000...\n",
      "Fetching records 52000 to 54000...\n",
      "Fetching records 54000 to 56000...\n",
      "Fetching records 56000 to 58000...\n",
      "Fetching records 58000 to 60000...\n",
      "Fetching records 60000 to 62000...\n",
      "Fetching records 62000 to 64000...\n",
      "Fetching records 64000 to 66000...\n",
      "Fetching records 66000 to 68000...\n",
      "Fetching records 68000 to 70000...\n",
      "Fetching records 70000 to 72000...\n",
      "Fetching records 72000 to 74000...\n",
      "Fetching records 74000 to 76000...\n",
      "Fetching records 76000 to 78000...\n",
      "Fetching records 78000 to 80000...\n",
      "Fetching records 80000 to 82000...\n",
      "Fetching records 82000 to 84000...\n",
      "Fetching records 84000 to 86000...\n",
      "Fetching records 86000 to 88000...\n",
      "Fetching records 88000 to 90000...\n",
      "Fetching records 90000 to 92000...\n",
      "Fetching records 92000 to 94000...\n",
      "Fetching records 94000 to 96000...\n",
      "Fetching records 96000 to 98000...\n",
      "Fetching records 98000 to 100000...\n",
      "Fetching records 100000 to 102000...\n",
      "Fetching records 102000 to 104000...\n",
      "Fetching records 104000 to 106000...\n",
      "Fetching records 106000 to 108000...\n",
      "Fetching records 108000 to 110000...\n",
      "Fetching records 110000 to 112000...\n",
      "Fetching records 112000 to 114000...\n",
      "Fetching records 114000 to 116000...\n",
      "Fetching records 116000 to 118000...\n",
      "Fetching records 118000 to 120000...\n",
      "Fetching records 120000 to 122000...\n",
      "Fetching records 122000 to 124000...\n",
      "Fetching records 124000 to 126000...\n",
      "Fetching records 126000 to 128000...\n",
      "Fetching records 128000 to 130000...\n",
      "Fetching records 130000 to 132000...\n",
      "Fetching records 132000 to 134000...\n",
      "Fetching records 134000 to 136000...\n",
      "Fetching records 136000 to 138000...\n",
      "Fetching records 138000 to 140000...\n",
      "Fetching records 140000 to 142000...\n",
      "Fetching records 142000 to 144000...\n",
      "Fetching records 144000 to 146000...\n",
      "Fetching records 146000 to 148000...\n",
      "Fetching records 148000 to 150000...\n",
      "Fetching records 150000 to 152000...\n",
      "Fetching records 152000 to 154000...\n",
      "Fetching records 154000 to 156000...\n",
      "Fetching records 156000 to 158000...\n",
      "Fetching records 158000 to 160000...\n",
      "Fetching records 160000 to 162000...\n",
      "Fetching records 162000 to 164000...\n",
      "Fetching records 164000 to 166000...\n",
      "Fetching records 166000 to 168000...\n",
      "Fetching records 168000 to 170000...\n",
      "Fetching records 170000 to 172000...\n",
      "Fetching records 172000 to 174000...\n",
      "Fetching records 174000 to 176000...\n",
      "Fetching records 176000 to 178000...\n",
      "Fetching records 178000 to 180000...\n",
      "Fetching records 180000 to 182000...\n",
      "Fetching records 182000 to 184000...\n",
      "Fetching records 184000 to 186000...\n",
      "Fetching records 186000 to 188000...\n",
      "Fetching records 188000 to 190000...\n",
      "Fetching records 190000 to 192000...\n",
      "Fetching records 192000 to 194000...\n",
      "Fetching records 194000 to 196000...\n",
      "Fetching records 196000 to 198000...\n",
      "Fetching records 198000 to 200000...\n",
      "Fetching records 200000 to 202000...\n",
      "Fetching records 202000 to 204000...\n",
      "Fetching records 204000 to 206000...\n",
      "Fetching records 206000 to 208000...\n",
      "Fetching records 208000 to 210000...\n",
      "Fetching records 210000 to 212000...\n",
      "Fetching records 212000 to 214000...\n",
      "Fetching records 214000 to 216000...\n",
      "Fetching records 216000 to 218000...\n",
      "Fetching records 218000 to 220000...\n",
      "Fetching records 220000 to 222000...\n",
      "Fetching records 222000 to 224000...\n",
      "Fetching records 224000 to 226000...\n",
      "Fetching records 226000 to 228000...\n",
      "Fetching records 228000 to 230000...\n",
      "Fetching records 230000 to 232000...\n",
      "Fetching records 232000 to 234000...\n",
      "Fetching records 234000 to 236000...\n",
      "Fetching records 236000 to 238000...\n",
      "Fetching records 238000 to 240000...\n",
      "Fetching records 240000 to 242000...\n",
      "Fetching records 242000 to 244000...\n",
      "Fetching records 244000 to 246000...\n",
      "Fetching records 246000 to 248000...\n",
      "Fetching records 248000 to 250000...\n",
      "Fetching records 250000 to 252000...\n",
      "Fetching records 252000 to 254000...\n",
      "Fetching records 254000 to 256000...\n",
      "Fetching records 256000 to 258000...\n",
      "Fetching records 258000 to 260000...\n",
      "Fetching records 260000 to 262000...\n",
      "Fetching records 262000 to 264000...\n",
      "Fetching records 264000 to 266000...\n",
      "Fetching records 266000 to 268000...\n",
      "Fetching records 268000 to 270000...\n",
      "Fetching records 270000 to 272000...\n",
      "Fetching records 272000 to 274000...\n",
      "Fetching records 274000 to 276000...\n",
      "Fetching records 276000 to 278000...\n",
      "Fetching records 278000 to 280000...\n",
      "Fetching records 280000 to 282000...\n",
      "Fetching records 282000 to 284000...\n",
      "Fetching records 284000 to 286000...\n",
      "Fetching records 286000 to 288000...\n",
      "Fetching records 288000 to 290000...\n",
      "Fetching records 290000 to 292000...\n",
      "Fetching records 292000 to 294000...\n",
      "Fetching records 294000 to 296000...\n",
      "Fetching records 296000 to 298000...\n",
      "Fetching records 298000 to 300000...\n",
      "Fetching records 300000 to 302000...\n",
      "Fetching records 302000 to 304000...\n",
      "Fetching records 304000 to 306000...\n",
      "Fetching records 306000 to 308000...\n",
      "Fetching records 308000 to 310000...\n",
      "Fetching records 310000 to 312000...\n",
      "Fetching records 312000 to 314000...\n",
      "Fetching records 314000 to 316000...\n",
      "Fetching records 316000 to 318000...\n",
      "Fetching records 318000 to 320000...\n",
      "Fetching records 320000 to 322000...\n",
      "Fetching records 322000 to 324000...\n",
      "Fetching records 324000 to 326000...\n",
      "Fetching records 326000 to 328000...\n",
      "Fetching records 328000 to 330000...\n",
      "Fetching records 330000 to 332000...\n",
      "Fetching records 332000 to 334000...\n",
      "Fetching records 334000 to 336000...\n",
      "Fetching records 336000 to 338000...\n",
      "Fetched a total of 337152 features.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(all_features, json_file)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m output_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malabama_2019_pr_data.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_json, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m---> 73\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "def get_total_count(base_url):\n",
    "    \"\"\"\n",
    "    Query the service to get the total record count.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'where': '1=1',\n",
    "        'returnCountOnly': 'true',\n",
    "        'f': 'json'\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    return data.get('count', 0)\n",
    "\n",
    "def main():\n",
    "    # Base URL for the Feature Service's query endpoint\n",
    "    base_url = 'https://geo.dot.gov/server/rest/services/Hosted/HPMS_Full_AL_2019/FeatureServer/0/query'\n",
    "    \n",
    "    # Get total number of records\n",
    "    total_count = get_total_count(base_url)\n",
    "    print(f\"Total records: {total_count}\")\n",
    "\n",
    "    # Set the batch size (the maximum number of records per request, typically 2000)\n",
    "    batch_size = 2000\n",
    "    all_features = []\n",
    "\n",
    "    # Loop over the data in batches using resultOffset and resultRecordCount\n",
    "    for offset in range(0, total_count, batch_size):\n",
    "        print(f\"Fetching records {offset} to {offset + batch_size}...\")\n",
    "        params = {\n",
    "            'where': '1=1',\n",
    "            'outFields': '*',\n",
    "            'f': 'geojson',  # request GeoJSON format\n",
    "            'resultOffset': offset,\n",
    "            'resultRecordCount': batch_size\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data at offset {offset}: HTTP {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            print(\"No more features returned; ending loop.\")\n",
    "            break\n",
    "\n",
    "        all_features.extend(features)\n",
    "        # Pause briefly to avoid overwhelming the server (optional)\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"Fetched a total of {len(all_features)} features.\")\n",
    "\n",
    "    # Convert the list of GeoJSON features into a DataFrame.\n",
    "    # This will flatten the 'properties' and other nested fields.\n",
    "    df = pd.json_normalize(all_features)\n",
    "\n",
    "    # Optionally, if you want to flatten geometry into separate columns,\n",
    "    # you might add something like the following (if applicable):\n",
    "    # if 'geometry.coordinates' in df.columns:\n",
    "    #     df[['longitude', 'latitude']] = pd.DataFrame(df['geometry.coordinates'].tolist(), index=df.index)\n",
    "\n",
    "    # Save the DataFrame to a CSV file.\n",
    "    output_csv = \"alabama_2019_pr_data.csv\"\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Data saved to {output_csv}\")\n",
    "    output_json = \"alabama_2019_pr_data.json\"\n",
    "    with open(output_json, \"w\") as json_file:\n",
    "        json.dump(all_features, json_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 345959\n",
      "Fetching records 0 to 2000...\n",
      "Fetching records 2000 to 4000...\n",
      "Fetching records 4000 to 6000...\n",
      "Fetching records 6000 to 8000...\n",
      "Fetching records 8000 to 10000...\n",
      "Fetching records 10000 to 12000...\n",
      "Fetching records 12000 to 14000...\n",
      "Fetching records 14000 to 16000...\n",
      "Fetching records 16000 to 18000...\n",
      "Fetching records 18000 to 20000...\n",
      "Fetching records 20000 to 22000...\n",
      "Fetching records 22000 to 24000...\n",
      "Fetching records 24000 to 26000...\n",
      "Fetching records 26000 to 28000...\n",
      "Fetching records 28000 to 30000...\n",
      "Fetching records 30000 to 32000...\n",
      "Fetching records 32000 to 34000...\n",
      "Fetching records 34000 to 36000...\n",
      "Fetching records 36000 to 38000...\n",
      "Fetching records 38000 to 40000...\n",
      "Fetching records 40000 to 42000...\n",
      "Fetching records 42000 to 44000...\n",
      "Fetching records 44000 to 46000...\n",
      "Fetching records 46000 to 48000...\n",
      "Fetching records 48000 to 50000...\n",
      "Fetching records 50000 to 52000...\n",
      "Fetching records 52000 to 54000...\n",
      "Fetching records 54000 to 56000...\n",
      "Fetching records 56000 to 58000...\n",
      "Fetching records 58000 to 60000...\n",
      "Fetching records 60000 to 62000...\n",
      "Fetching records 62000 to 64000...\n",
      "Fetching records 64000 to 66000...\n",
      "Fetching records 66000 to 68000...\n",
      "Fetching records 68000 to 70000...\n",
      "Fetching records 70000 to 72000...\n",
      "Fetching records 72000 to 74000...\n",
      "Fetching records 74000 to 76000...\n",
      "Fetching records 76000 to 78000...\n",
      "Fetching records 78000 to 80000...\n",
      "Fetching records 80000 to 82000...\n",
      "Fetching records 82000 to 84000...\n",
      "Fetching records 84000 to 86000...\n",
      "Fetching records 86000 to 88000...\n",
      "Fetching records 88000 to 90000...\n",
      "Fetching records 90000 to 92000...\n",
      "Fetching records 92000 to 94000...\n",
      "Fetching records 94000 to 96000...\n",
      "Fetching records 96000 to 98000...\n",
      "Fetching records 98000 to 100000...\n",
      "Fetching records 100000 to 102000...\n",
      "Fetching records 102000 to 104000...\n",
      "Fetching records 104000 to 106000...\n",
      "Fetching records 106000 to 108000...\n",
      "Fetching records 108000 to 110000...\n",
      "Fetching records 110000 to 112000...\n",
      "Fetching records 112000 to 114000...\n",
      "Fetching records 114000 to 116000...\n",
      "Fetching records 116000 to 118000...\n",
      "Fetching records 118000 to 120000...\n",
      "Fetching records 120000 to 122000...\n",
      "Fetching records 122000 to 124000...\n",
      "Fetching records 124000 to 126000...\n",
      "Fetching records 126000 to 128000...\n",
      "Fetching records 128000 to 130000...\n",
      "Fetching records 130000 to 132000...\n",
      "Fetching records 132000 to 134000...\n",
      "Fetching records 134000 to 136000...\n",
      "Fetching records 136000 to 138000...\n",
      "Fetching records 138000 to 140000...\n",
      "Fetching records 140000 to 142000...\n",
      "Fetching records 142000 to 144000...\n",
      "Fetching records 144000 to 146000...\n",
      "Fetching records 146000 to 148000...\n",
      "Fetching records 148000 to 150000...\n",
      "Fetching records 150000 to 152000...\n",
      "Fetching records 152000 to 154000...\n",
      "Fetching records 154000 to 156000...\n",
      "Fetching records 156000 to 158000...\n",
      "Fetching records 158000 to 160000...\n",
      "Fetching records 160000 to 162000...\n",
      "Fetching records 162000 to 164000...\n",
      "Fetching records 164000 to 166000...\n",
      "Fetching records 166000 to 168000...\n",
      "Fetching records 168000 to 170000...\n",
      "Fetching records 170000 to 172000...\n",
      "Fetching records 172000 to 174000...\n",
      "Fetching records 174000 to 176000...\n",
      "Fetching records 176000 to 178000...\n",
      "Fetching records 178000 to 180000...\n",
      "Fetching records 180000 to 182000...\n",
      "Fetching records 182000 to 184000...\n",
      "Fetching records 184000 to 186000...\n",
      "Fetching records 186000 to 188000...\n",
      "Fetching records 188000 to 190000...\n",
      "Fetching records 190000 to 192000...\n",
      "Fetching records 192000 to 194000...\n",
      "Fetching records 194000 to 196000...\n",
      "Fetching records 196000 to 198000...\n",
      "Fetching records 198000 to 200000...\n",
      "Fetching records 200000 to 202000...\n",
      "Fetching records 202000 to 204000...\n",
      "Fetching records 204000 to 206000...\n",
      "Fetching records 206000 to 208000...\n",
      "Fetching records 208000 to 210000...\n",
      "Fetching records 210000 to 212000...\n",
      "Fetching records 212000 to 214000...\n",
      "Fetching records 214000 to 216000...\n",
      "Fetching records 216000 to 218000...\n",
      "Fetching records 218000 to 220000...\n",
      "Fetching records 220000 to 222000...\n",
      "Fetching records 222000 to 224000...\n",
      "Fetching records 224000 to 226000...\n",
      "Fetching records 226000 to 228000...\n",
      "Fetching records 228000 to 230000...\n",
      "Fetching records 230000 to 232000...\n",
      "Fetching records 232000 to 234000...\n",
      "Fetching records 234000 to 236000...\n",
      "Fetching records 236000 to 238000...\n",
      "Fetching records 238000 to 240000...\n",
      "Fetching records 240000 to 242000...\n",
      "Fetching records 242000 to 244000...\n",
      "Fetching records 244000 to 246000...\n",
      "Fetching records 246000 to 248000...\n",
      "Fetching records 248000 to 250000...\n",
      "Fetching records 250000 to 252000...\n",
      "Fetching records 252000 to 254000...\n",
      "Fetching records 254000 to 256000...\n",
      "Fetching records 256000 to 258000...\n",
      "Fetching records 258000 to 260000...\n",
      "Fetching records 260000 to 262000...\n",
      "Fetching records 262000 to 264000...\n",
      "Fetching records 264000 to 266000...\n",
      "Fetching records 266000 to 268000...\n",
      "Fetching records 268000 to 270000...\n",
      "Fetching records 270000 to 272000...\n",
      "Fetching records 272000 to 274000...\n",
      "Fetching records 274000 to 276000...\n",
      "Fetching records 276000 to 278000...\n",
      "Fetching records 278000 to 280000...\n",
      "Fetching records 280000 to 282000...\n",
      "Fetching records 282000 to 284000...\n",
      "Fetching records 284000 to 286000...\n",
      "Fetching records 286000 to 288000...\n",
      "Fetching records 288000 to 290000...\n",
      "Fetching records 290000 to 292000...\n",
      "Fetching records 292000 to 294000...\n",
      "Fetching records 294000 to 296000...\n",
      "Fetching records 296000 to 298000...\n",
      "Fetching records 298000 to 300000...\n",
      "Fetching records 300000 to 302000...\n",
      "Fetching records 302000 to 304000...\n",
      "Fetching records 304000 to 306000...\n",
      "Fetching records 306000 to 308000...\n",
      "Fetching records 308000 to 310000...\n",
      "Fetching records 310000 to 312000...\n",
      "Fetching records 312000 to 314000...\n",
      "Fetching records 314000 to 316000...\n",
      "Fetching records 316000 to 318000...\n",
      "Fetching records 318000 to 320000...\n",
      "Fetching records 320000 to 322000...\n",
      "Fetching records 322000 to 324000...\n",
      "Fetching records 324000 to 326000...\n",
      "Fetching records 326000 to 328000...\n",
      "Fetching records 328000 to 330000...\n",
      "Fetching records 330000 to 332000...\n",
      "Fetching records 332000 to 334000...\n",
      "Fetching records 334000 to 336000...\n",
      "Fetching records 336000 to 338000...\n",
      "Fetching records 338000 to 340000...\n",
      "Fetching records 340000 to 342000...\n",
      "Fetching records 342000 to 344000...\n",
      "Fetching records 344000 to 346000...\n",
      "Fetched a total of 345959 features.\n",
      "Data saved to alabama_2023_pr_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "def get_total_count(base_url):\n",
    "    \"\"\"\n",
    "    Query the service to get the total record count.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'where': '1=1',\n",
    "        'returnCountOnly': 'true',\n",
    "        'f': 'json'\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    data = response.json()\n",
    "    return data.get('count', 0)\n",
    "\n",
    "def fetch_data(base_url, batch_size, total_count):\n",
    "    \"\"\"\n",
    "    Fetch data from the API in batches and return the collected features.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    for offset in range(0, total_count, batch_size):\n",
    "        print(f\"Fetching records {offset} to {offset + batch_size}...\")\n",
    "        params = {\n",
    "            'where': '1=1',\n",
    "            'outFields': '*',\n",
    "            'f': 'json',\n",
    "            'resultOffset': offset,\n",
    "            'resultRecordCount': batch_size\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data at offset {offset}: HTTP {response.status_code}\")\n",
    "            break\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            print(\"No more features returned; ending loop.\")\n",
    "            break\n",
    "        all_features.extend(features)\n",
    "        time.sleep(1)  # Avoid overwhelming the server\n",
    "    return all_features\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    \"\"\"\n",
    "    Save the collected data to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json.dump(data, json_file)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def main():\n",
    "    base_url = 'https://geo.dot.gov/server/rest/services/Hosted/HPMS_Full_AL_2023/FeatureServer/0/query'\n",
    "    batch_size = 2000\n",
    "    total_count = get_total_count(base_url)\n",
    "    print(f\"Total records: {total_count}\")\n",
    "    all_features = fetch_data(base_url, batch_size, total_count)\n",
    "    print(f\"Fetched a total of {len(all_features)} features.\")\n",
    "    save_to_json(all_features, \"alabama_2023_pr_data.json\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data successfully converted to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON\n",
    "with open(\"alabama_2019_pr_data.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Flatten JSON\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"alabama_2019_pr_data.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"JSON data successfully converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
